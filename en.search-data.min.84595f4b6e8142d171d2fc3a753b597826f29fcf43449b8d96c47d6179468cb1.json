[{"id":0,"href":"/docs/linux/","title":"Linux","section":"Docs","content":"Introduction #  Linux 相关的学习笔记\n"},{"id":1,"href":"/docs/golang/","title":"Go语言笔记","section":"Docs","content":"Introduction #  Golang 相关的学习笔记\n"},{"id":2,"href":"/docs/database/","title":"数据库相关","section":"Docs","content":"Introduction #  "},{"id":3,"href":"/docs/nginx/","title":"Nginx","section":"Docs","content":"Introduction #  "},{"id":4,"href":"/docs/etcd/","title":"Etcd","section":"Docs","content":"Introduction #  Etcd 相关的学习笔记\n"},{"id":5,"href":"/docs/queue/","title":"消息队列","section":"Docs","content":"Introduction #  消息队列相关的学习笔记\n"},{"id":6,"href":"/docs/elasticsearch/","title":"Elasticsearch","section":"Docs","content":"Introduction #  "},{"id":7,"href":"/docs/kubernetes/","title":"Kubernetes","section":"Docs","content":"Introduction #  Kubernetes 相关的学习笔记\n"},{"id":8,"href":"/docs/algorithm/","title":"算法知识","section":"Docs","content":"Introduction #  "},{"id":9,"href":"/docs/interview/","title":"面试相关笔记","section":"Docs","content":"Introduction #  "},{"id":10,"href":"/docs/material/","title":"学习资料","section":"Docs","content":"Introduction #  "},{"id":11,"href":"/docs/other/","title":"其他笔记","section":"Docs","content":"Introduction #  "},{"id":12,"href":"/docs/life/","title":"生活日志","section":"Docs","content":"Introduction #  "},{"id":13,"href":"/docs/golang/go-pkg/","title":"go第三方库列表","section":"Go语言笔记","content":" go服务端开发中避免不了使用第三方库，因为第三方库可以避免重复造轮子，大大的提高了开发效率， 这篇文章收集了各种有意思额go语言第三方库，方便开发需要时查找\n go语言实现的lua虚拟机 #    github.com/yuin/gopher-lua\n ElasticSearch Hook for Logrus #    github.com/sohlich/elogrus\n Actor模型go实现 #    github.com/AsynkronIT/protoactor-go\n Go便捷转换器（sql -\u0026gt; struct） #    github.com/airplayx/gormat\n Go语言的RPC服务治理框架 #    github.com/smallnest/rpcx\n go读取Excel表 #    github.com/qax-os/excelize\n go 爬虫框架colly #    github.com/gocolly/colly\n go底层操作系统交互补充包 #    github.com/golang/sys\n 双数组树go实现 #    github.com/adamzy/cedar-go\n go程序优雅重启 #    github.com/cloudflare/tableflip\n 基于zap封装的log包 #    github.com/georgehao/log\n go一致性哈希包 #    github.com/stathat/consistent\n bilibili开源IM框架 #    github.com/Terry-Mao/goim\n golang tcp 框架（仿gin） #    https://github.com/fwhezfwhez/tcpx\n 是一个轻量、快速的基于 Reactor 模式的非阻塞 TCP 网络库 / websocket server #    github.com/Allenxuxu/gev\n go分布式服务框架 #    github.com/skynetservices/skynet-archive\n sql代码生成：sqlc #    github.com/kyleconroy/sqlc\n go http路由 #    github.com/gorilla/mux\n go 测试库: gostub #    github.com/prashantv/gostub\n 唯一id生成golang库 #    github.com/satori/go.uuid\n golang缓存库： gcache #    github.com/bluele/gcache\n go jwt认证 #    github.com/dgrijalva/jwt-go\n go爬虫辅助，收集页面所有url #    github.com/JackDanger/collectlinks\n bilibili开源微服务框架：Kratos #    github.com/go-kratos/kratos\n go-micro微服务框架 #    github.com/micro/go-micro\n go web 框架：neo #   github.com/ivpusic/neo\ngim聊天系统 #    github.com/alberliu/gim\n mysql同步elasticsearch #    github.com/go-mysql-org/go-mysql-elasticsearch\n 左倾红黑树 #    github.com/petar/GoLLRB\n oklog #    github.com/oklog/oklog\n golang时间库：carbon #    github.com/uniplaces/carbon\n go协程池：ants #    github.com/panjf2000/ants\n go基准测试框架 #    github.com/fperf/fperf\n go-kit代码生成器 #    github.com/metaverse/truss\n 中文分词 #    github.com/huichen/sego\n 生成带文字的png图片 #    github.com/golang/freetype\n chart图表库 #    github.com/wcharczuk/go-chart\n 人脸识别库 #    github.com/Kagami/go-face\n"},{"id":14,"href":"/docs/database/mongodb/","title":"MongoDB的一些操作记录","section":"数据库相关","content":" 本文记录MongoDB使用过程中，因需求需要进行一些不常用的操作，如创建用户，导出数据，数据备份恢复等运维层面的技术知识， 后续有遇到继续往文章后面添加，以备不时之需，可来此进行查阅\n  MongoDB创建用户  # 用户名xxx, 密码123, 角色权限：readWrite(读写), 数据库：xxx db.createUser({user:\u0026#39;xxx\u0026#39;, pwd:\u0026#39;123\u0026#39;, roles:[{ role: \u0026#34;readWrite\u0026#34;, db: \u0026#34;xxx\u0026#34; }]})  MongoDB导出数据  # 数据库：xxxdb, 用户名：xxx, 密码：123, 表名：players, -f 需要导出的字段... --type=csv(导出格式) -o ./data.csv(导出路径) mongoexport -d xxxdb -u xxx -p 123 -c players -f _id,data.ip,data.createTime,data.lastLoginTime,data.resource.1,data.resource.2,data.resource.4,data.VideoTotal,data.withdraw.withdrawTotal --type=csv -o ./data.csv # 导出的Excel表中时间戳转成时间字符串 =TEXT((C2+8*3600)/86400+70*365+19,\u0026#34;yyyy-mm-dd hh:mm:ss\u0026#34;)  MongoDB备份数据  # 数据库名： xxxdb, 用户名：xxx, 密码： 123, 备份文件路径：/root/workspace/mongo/backup mongodump -d xxxdb -o /root/workspace/mongo/backup -u xxx -p 123 "},{"id":15,"href":"/docs/nginx/nginxop/","title":"Nginx命令操作记录","section":"Nginx","content":" 重新load配置 nginx -s reload 热部署   先替换nginx二进制文件，然后发送kill -USR2 进程号，会启动新master 的进程\n然后向老进程发送信号让其优雅的关闭work进程 kill -WINCH 进程号 , 老的master进程会保留防止回退\n "},{"id":16,"href":"/docs/other/mac/","title":"其他记录","section":"其他笔记","content":" 其他杂乱的操作记录，供必要时查阅\n Mac app损坏：\n#  sudo xattr -r -d com.apple.quarantine /Applications/CleanMyMac\\ X.app/\n好用插件记录 #   Annotate 具体到每一行代码是谁提交的 "},{"id":17,"href":"/docs/material/reference/","title":"参考博客文献","section":"学习资料","content":" 本文收集一下博客文献的链接，供学习参考\n    golang gin demo\n   go高效直播服务器\n   go学习资源合集\n   验证码生成go实现\n   go学习线路图\n   简易图像服务器go实现\n   书籍《go语言高级编程》在线阅读\n   RabbitMQ高频面试题\n   Elasticsearch学习笔记\n   linux awk命令使用教程\n "},{"id":18,"href":"/docs/interview/interview/","title":"面经","section":"面试相关笔记","content":" 这里记录我一直以来的面试经历\n 游乐学 #  2020-05\n 小孩子教学类游戏\n  golang怎么管理调度协程的 go指针和c++指针的区别 golang内存泄漏有哪些情况？ 数组和slice的区别 项目有没有用redis作缓存 Linux下怎么调试找bug 用什么命令查看Linux下一个端口的状态  lsof -i :port_number |grep \u0026quot;(LISTEN)\u0026quot; netstat  怎么查找/替换指定目录下所有文件的指定内容  sed -i s/yyyy/xxxx/g `grep yyyy -rl --include=\u0026quot;*.txt\u0026quot; ./`  点云（心娱） #  2020-06\n 游戏+直播\n  项目经验 遇到的难题以及解决方法   信言 #  2020-06\n 狼人杀\n  红黑树 MySQL事务 gRPC的具体内容 TCP/IP协议 40亿个不同的数排序（桶排序，一个比特位一个桶）   数字广东 #  2020-07\n 驻数字广东的外包人员\n  协程之间的同步和锁 channel的使用 项目架构图 登录流程 如何防止多次登录请求 单链表反转 C++和golang的区别 map的底层实现 游戏AI控制脚本的设计模式 项目进程间通信的协议HTTP还是socket   银月互娱 （offer） #  2020-07\n 赌博类游戏app，海外外包\n  解耦（场景：同时生成很多张照片）【降低两者之间的联系】 多协程读写map注意事项【加锁】 new和make的区别【make针对slice，map， chan】 面向对象通过什么实现（组合/继承/接口）【golang 使用组合的方式实现继承 ，从而实现面向对象】 MongoDB索引 MongoDB聚合 slice是否可以作为map键 s为字符串，是s[0]表示啥？ 同时广播消息给10万个socket 项目架构图 defer输出顺序 重写父类函数 程序找问题：未初始化map waitGroup死锁问题   聚游网络 （offer） #  2020-07\n 网赚类轻度休闲手游\n  啥都没问  艾美科技 #  2021-04-08\n 投币式K歌机\n  快排 介绍最拿手的项目 会员登录服怎么去设计实现 MongoDB objectID 抛出异常， 怎么向上级抛出异常 怎么捕获异常 defer的什么时候输出， sys.Exit()还会不会输出 树的遍历方式   金山电话一面 #  2021-04-10\n wps办公软件\n  自我介绍 golang的面向对象 golang的多态怎么实现（不同的结构体实现同一个接口） golang的闭包，闭包的概念 golang自己实现读写锁 channal底层实现 字符串里的字符统计 golang内存逃逸 数组和切片的区别 golang程序有没有做性能监控（比如协程的数量） init函数，只使用包的init函数怎么导入包 进程间怎么通信（rpc） linux 查询筛选今天的日志 查询端口占用情况 资源占用高怎么排查问题 MySQL索引，B+树的时间复杂度，B+树和B树的区别 MongoDB分片（3个节点，6个分片，数据是怎么样的） MongoDB和Redis的区别 怎么解决缓存一致性 缓存击穿 数据库中配置数据忘了提交，导致缓存穿透怎么优化 redis发布订阅 Redis分布式锁怎么实现 线上服部署的流程 有没有用过大数据相关，推荐算法 微服务的理解 自己项目架构是怎样的？有什么弊端？ make和new的区别 Elasticsearch的分片 有没有用过Elasticsearch数据从MySQL导入 测试服不同版本怎么隔离 场景优化：电商大量图片经常被请求，带宽过高怎么优化？ 场景优化：大量读写配置怎么降低QPS 你们项目的QPS多高？ 你有什么要问我们的吗？   致悦科技 #  2021-04-10\n 卡牌手游\n  没面试，过去当主程  木木互娱 #  2021-04-15\n 游戏，CDN开发\n  协程，高并发   千音科技 #  2021-04-15\n 视频直播\n  redis集群 redis事务 "},{"id":19,"href":"/docs/interview/plan/","title":"面试准备","section":"面试相关笔记","content":" 这里记录我一直以来的面试准备知识点，会不断优化迭代\n Golang #  go协程 #   协程之间的同步的几种方法  互斥锁: Mutex channel （生产消费模型） WaitGroup （add, done和wait）  golang怎么管理调度协程的?  基于GPM模型实现 goroutine 并非传统意义上的协程，现在主流的线程模型分三种：内核级线程模型、用户级线程模型和两级线程模型（也称混合型线程模型），传统的协程库属于用户级线程模型，而 goroutine 和它的 Go Scheduler 在底层实现上其实是属于两级线程模型。 在 Go 语言中，每一个 goroutine 是一个独立的执行单元，相较于每个 OS 线程固定分配 2M 内存的模式，goroutine 的栈采取了动态扩容方式， 初始时仅为2KB，随着任务执行按需增长，最大可达 1GB（64 位机器最大是 1G，32 位机器最大是 256M），且完全由 golang 自己的调度器 Go Scheduler 来调度。此外，GC 还会周期性地将不再使用的内存回收，收缩栈空间。 因此，Go 程序可以同时并发成千上万个 goroutine 是得益于它强劲的调度器和高效的内存模型。 //----------------------------------------------------------------------- GPM G: 表示 Goroutine，每个 Goroutine 对应一个 G 结构体，G 存储 Goroutine 的运行堆栈、状态以及任务函数，可重用。G 并非执行体，每个 G 需要绑定到 P 才能被调度执行。 P: Processor，表示逻辑处理器， 对 G 来说，P 相当于 CPU 核，G 只有绑定到 P(在 P 的 local runq 中)才能被调度。对 M 来说，P 提供了相关的执行环境(Context)，如内存分配状态(mcache)，任务队列(G)等，P 的数量决定了系统内最大可并行的 G 的数量（前提：物理 CPU 核数 \u0026gt;= P 的数量），P 的数量由用户设置的 GOMAXPROCS 决定，但是不论 GOMAXPROCS 设置为多大，P 的数量最大为 256。 M: Machine，OS 线程抽象，代表着真正执行计算的资源，在绑定有效的 P 后，进入 schedule 循环；而 schedule 循环的机制大致是从 Global 队列、P 的 Local 队列以及 wait 队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 goexit 做清理工作并回到 M，如此反复。M 并不保留 G 状态，这是 G 可以跨 M 调度的基础，M 的数量是不定的，由 Go Runtime 调整，为了防止创建过多 OS 线程导致系统调度不过来，目前默认最大限制为 10000 个。 每个 P 维护一个 G 的本地队列； 当一个 G 被创建出来，或者变为可执行状态时，就把他放到 P 的本地可执行队列中，如果满了则放入Global； 当一个 G 在 M 里执行结束后，P 会从队列中把该 G 取出；如果此时 P 的队列为空，即没有其他 G 可以执行， M 就随机选择另外一个 P，从其可执行的 G 队列中取走一半。  当通过 go 关键字创建一个新的 goroutine 的时候，它会优先被放入 P 的本地队列。为了运行 goroutine，M 需要持有（绑定）一个 P，接着 M 会启动一个 OS 线程，循环从 P 的本地队列里取出一个 goroutine 并执行。执行调度算法：当 M 执行完了当前 P 的 Local 队列里的所有 G 后，P 也不会就这么在那划水啥都不干，它会先尝试从 Global 队列寻找 G 来执行，如果 Global 队列为空，它会随机挑选另外一个 P，从它的队列里中拿走一半的 G 到自己的队列中执行。 用户态阻塞/唤醒 当 goroutine 因为 channel 操作阻塞时，对应的 G 会被放置到某个 wait 队列(如 channel 的 waitq)，该 G 的状态由_Gruning 变为 _Gwaitting ，而 M 会跳过该 G 尝试获取并执行下一个 G，如果此时没有 runnable 的 G 供 M 运行，那么 M 将解绑 P，并进入 sleep 状态；当阻塞的 G 被另一端的 G2 唤醒时（比如 channel 的可读/写通知），G 被标记为 runnable，尝试加入 G2 所在 P 的 runnext，然后再是 P 的 Local 队列和 Global 队列。  主协程如何等其余协程完再操作  用channel控制 用sync.WaitGroup  golang内存泄漏有哪些情况？  外部资源是不可以GC掉的，如：打开文件，数据库，http请求等 短时间内实例化过多对象等  channel的使用 go指针和c++指针的区别  c++指针可以做算术运算  C++和golang的区别 数组和slice的区别 map的底层实现  散列表，即哈希表  多协程读写map注意事项  加锁  slice是否可以作为map键  map key 必须是可比较的类型，语言规范中定义了可比较的类型：boolean, numeric, string, pointer, channel, interface, 以及仅包含这些类型的struct和array 。不能作为map key的类型有：slice，map, function。  new和make的区别  make针对slice，map， chan new返回的是指向Type的指针。 make直接返回的是Type类型值 总结： new会分配结构空间，并初始化为清空为零，不进一步初始化 new之后需要一个指针来指向这个结构 make会分配结构空间及其附属空间，并完成其间的指针初始化 make返回这个结构空间，不另外分配一个指针   面向对象通过什么实现（组合/继承/接口）  golang 使用组合的方式实现继承 ，从而实现面向对象  defer输出顺序  FILO，后进先出，即下到上 最先声明的最后输出  select用于干什么？  用于处理异步IO问题  context包的用途  用于控制goroutine的生命周期。 当一个计算任务被goroutine承接了之后，由于某种原因（超时，或者强制退出） 我们希望中止这个goroutine的计算任务，那么就用得到这个Context了。  sync.pool  为了复用已经使用过的对象，来达到优化内存使用和回收的目的  重写父类函数 waitGroup死锁问题 项目进程间通信的协议HTTP还是socket s为字符串，是s[0]表示啥？  如果 s 是一个字符串，那么s[0] 表示 s 的第一个 byte，长度固定：1个字节。  同时广播消息给10万个socket   gin源码解读 #   Linux #   用什么命令查看Linux下一个端口的状态  答： lsof -i :端口号 | grep \u0026quot;(LISTEN)\u0026quot; // 查看对应端口的占用情况 netstat -nultp // 查看所有端口的占用情况 netstat -anp | grep 端口号 // 查看对应端口的占用情况  怎么查找/替换指定目录下所有文件的指定内容  sed -i s/yyyy/xxxx/g `grep yyyy -rl --include=\u0026quot;*.txt\u0026quot; ./`  MySQL #   MySQL事务  在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。 事务用来管理 insert,update,delete 语句 // ----------------------------------------------------- 原子性： 一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性： 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性： 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。  MySQL主键索引和辅助索引的区别 inonedb为啥用b+树  为什么说B+树比B树更适合数据库索引？ 1、 B+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。 2、B+树的查询效率更加稳定：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。 3、由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。 PS：我在知乎上看到有人是这样说的,我感觉说的也挺有道理的： 他们认为数据库索引采用B+树的主要原因是：B树在提高了IO性能的同时并没有解决元素遍历的我效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低。  索引分析 MySQL联合索引 分表（水平分表，垂直分表） 有一张表，有商店ID，既要按照商店查询，也要按照商品查询。求分表策略。 MySQL深翻页问题如何解决， limit m, n   MongoDB #   MongoDB索引 聚合   Redis #  Redis缓存 #   缓存穿透 缓存雪崩 缓存一致性问题  Redis队列 #  哈希表实现原理（Redis的哈希表扩容） #  Redis分布式锁 #  Redis zrange复杂度 #   TiDB #   RabbitMQ #   Elasticsearch #   Etcd #   Nginx #   TCP/IP #   与udp的区别  tcp传输的是数据流，而udp是数据包，tcp会进过三次握手，udp不需要  HTTP #   http完整请求 错误码  400 bad request，请求报文存在语法错误 401 unauthorized，表示发送的请求需要有通过 HTTP 认证的认证信息 403 forbidden，表示对请求资源的访问被服务器拒绝 404 not found，表示在服务器上没有找到请求的资源  WebSocket #   websocket 不支持并发写   protobuf #   protobuf和json比较的优势   rpc #   gRpc的具体内容 rpc通信的协议是HTTP还是socket   shell #   数据结构 #  红黑树 #  B树的性质 #  定义任意非叶子结点最多只有M个儿子，且M\u0026gt;2； 根结点的儿子数为[2, M]； 除根结点以外的非叶子结点的儿子数为[M/2, M]； 每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字） 非叶子结点的关键字个数=指向儿子的指针个数-1； 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] \u0026lt; K[i+1]； 非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 所有叶子结点位于同一层； B+树的性质(下面提到的都是和B树不相同的性质) #  非叶子节点的子树指针与关键字个数相同； 非叶子节点的子树指针p[i],指向关键字值属于[k[i],k[i+1]]的子树.(B树是开区间,也就是说B树不允许关键字重复,B+树允许重复)； 为所有叶子节点增加一个链指针； 所有关键字都在叶子节点出现(稠密索引). (且链表中的关键字恰好是有序的)； 非叶子节点相当于是叶子节点的索引(稀疏索引),叶子节点相当于是存储(关键字)数据的数据层； 更适合于文件系统；  为什么MySQL数据库索引选择使用B+树？\n其他 #  解耦 （场景：同时生成很多张照片）【降低两者之间的联系】 #  稳定排序和不稳定排序 #  RBAC模型的分析与实现 #  RBAC全称为基于角色的访问控制模型（Role-based access control），在该模型中，通过让权限与角色关联来实现授权，给用户分配一系列的角色来让注册用户得到这些角色对应的权限，使系统权限分配更加方便。我们在一般的大型系统开发中，几乎都要考虑权限控制的相关问题，诸如：系统资源权限、用户行为权限等，此类问题的实现通常需要数据库在设计时做出考虑，经过IT届各种大佬的长期实践后，总结出了较为通用的针对权限控制的RBAC设计模型。RBAC不是某种技术框架，它类似于设计模式，是当下流行的一种数据库（表）设计的思想，它能通过为用户分配角色来实现权限的分配，只要你的数据库设计满足这种思想便可说你的数据库使用的是RBAC模型。  面试题 #    40亿个不同的数排序 桶排序，一个比特位一个桶\n  单链表反转\n  给定a,b两个文件，各存放50亿个url，每个url各占64字节，内存限制4G，让你找出a, b文件共同url\n "},{"id":20,"href":"/docs/interview/faq/","title":"面试灵魂拷问","section":"面试相关笔记","content":" 本文收集一些面试golang服务端开发的问题和答案，以及一些知识点的参考文章等，让即将面试的小伙伴有佛脚可抱。 包括但不限于Linux， golang， 数据库， nginx， etcd， Redis， http， 消息队列，等等。\n 问答集 #   Q1: Linux的磁盘管理 A:\n  Q2: Linux有哪些进程通信方式，五大件 A:\n  Q3: Linux的共享内存如何实现，大概说了一下 A:\n  Q4: 共享内存实现的具体步骤   Q5: socket网络编程，说一下TCP的三次握手和四次挥手   Q6:如何把docker讲的很清楚   Q7:cgroup在linux的具体实现   Q8:多线程用过哪些   Q9:MySQL索引的实现，innodb的索引，b+树索引是怎么实现的，为什么用b+树做索引节点，一个节点存了多少数据，怎么规定大小，与磁盘页对应   Q10:MySQL的事务隔离级别，分别解决什么问题   Q11:Redis了解么，如果Redis有1亿个key，使用keys命令是否会影响线上服务，我说会，因为是单线程模型，可以部署多个节点。   Q12:知不知道有一条命令可以实现上面这个功能   Q13:Redis的持久化方式，aod和rdb，具体怎么实现，追加日志和备份文件，底层实现原理   Q14:Redis的list是怎么实现的，我说用ziplist+quicklist实现的，ziplist压缩空间，quicklist实现链表   Q15:sortedset怎么实现的，使用dict+skiplist实现的，问我skiplist的数据结构，大概说了下是个实现简单的快速查询结构。   Q16:了解什么消息队列，rmq和kafka   Q17:线程池   Q18:操作系统的进程通信方式，僵尸进程和孤儿进程是什么，如何避免僵尸进程，我说让父进程显示通知，那父进程怎么知道子进程结束了   Q19:计算机网络TCP和UDP有什么区别，为什么迅雷下载是基于UDP的，我说FTP是基于TCP，而迅雷是p2p不需要TCP那么可靠的传输保证。   Q20:操作系统的死锁必要条件，如何避免死锁   Q21:写一个LRU的缓存，需要完成超时淘汰和LRU淘汰。   Q22: get和post的区别？ A： https://blog.csdn.net/kebi007/article/details/103059900\n  Q23: Redis 问题集 A： https://blog.csdn.net/Design407/article/details/103242874\n  Q24: 消息中间件面试题31道RabbitMQ+ActiveMQ+Kafka A: https://www.jianshu.com/p/0a322b2bba2a\n"},{"id":21,"href":"/docs/golang/channel/","title":"channel注意事项","section":"Go语言笔记","content":" channel是go语言编程中必不可少的元素，但对不同状态的channel作read，write和close操作会有不同的结果， 稍有操作不当，将导致系统 panic，所以本文介绍了channel不同状态的操作结果\n channel不同状态的操作结果： #     操作 channel状态 结果     Read nil 阻塞    打开且非空 输出值    打开但空 阻塞    关闭的 \u0026lt;默认值\u0026gt;, false    只写 编译错误   -     Write nil 阻塞    打开的但填满 阻塞    打开的且不满 写入值    关闭的 panic    只读 编译错误   -     close nil panic    打开且非空 关闭channel；读取成功，直到通道耗尽，然后读取产生的默认值    打开但空 关闭channel；读到生产者的默认值    关闭的 panic    只读 编译错误   "},{"id":22,"href":"/docs/elasticsearch/elasticsearch-install/","title":"Elasticsearch部署","section":"Elasticsearch","content":" Elasticsearch是一个开源的分布式、RESTful 风格的搜索和数据分析引擎，它的底层是开源库Apache Lucene。 Lucene 可以说是当下最先进、高性能、全功能的搜索引擎库——无论是开源还是私有，但它也仅仅只是一个库。 本文记录Linux上Elasticsearch的安装配置等部署流程\n 下载Elasticsearch #  wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz 创建用户 #  groupadd esGroup useradd user -g esGroup -p password 权限分配 #  cd /usr/local chown -R esUser:esGroup elasticsearch-7.1.0 vim /etc/security/limits.conf * soft nofile 65536 * hard nofile 65536 修改系统配置 #  vim /etc/sysctl.conf vm.max_map_count=262144 sysctl -p 修改elasticsearch配置(重点关注7项) #  # ======================== Elasticsearch Configuration ========================= # # NOTE: Elasticsearch comes with reasonable defaults for most settings. # Before you set out to tweak and tune the configuration, make sure you # understand what are you trying to accomplish and the consequences. # # The primary way of configuring a node is via this file. This template lists # the most important settings you may want to configure for a production cluster. # # Please consult the documentation for further information on configuration options: # https://www.elastic.co/guide/en/elasticsearch/reference/index.html # # ---------------------------------- Cluster ----------------------------------- # # Use a descriptive name for your cluster: # cluster.name: yourscat-es-cluster //-------------(1)--------------------- # # ------------------------------------ Node ------------------------------------ # # Use a descriptive name for the node: # node.name: node-1 //-------------(2)--------------------- # # Add custom attributes to the node: # #node.attr.rack: r1 # # ----------------------------------- Paths ------------------------------------ # # Path to directory where to store the data (separate multiple locations by comma): # path.data: /usr/local/elasticsearch-7.1.0/data //-------------(3)--------------------- # # Path to log files: # path.logs: /usr/local/elasticsearch-7.1.0/logs //-------------(4)--------------------- # # ----------------------------------- Memory ----------------------------------- # # Lock the memory on startup: # #bootstrap.memory_lock: true # # Make sure that the heap size is set to about half the memory available # on the system and that the owner of the process is allowed to use this # limit. # # Elasticsearch performs poorly when the system is swapping the memory. # # ---------------------------------- Network ----------------------------------- # # Set the bind address to a specific IP (IPv4 or IPv6): # network.host: 0.0.0.0 //-------------(5)--------------------- # # Set a custom port for HTTP: # http.port: 9200 //-------------(6)--------------------- # # For more information, consult the network module documentation. # # --------------------------------- Discovery ---------------------------------- # # Pass an initial list of hosts to perform discovery when this node is started: # The default list of hosts is [\u0026quot;127.0.0.1\u0026quot;, \u0026quot;[::1]\u0026quot;] # #discovery.seed_hosts: [\u0026quot;host1\u0026quot;, \u0026quot;host2\u0026quot;] # # Bootstrap the cluster using an initial set of master-eligible nodes: # cluster.initial_master_nodes: [\u0026quot;node-1\u0026quot;] //-------------(7)--------------------- # # For more information, consult the discovery and cluster formation module documentation. # # ---------------------------------- Gateway ----------------------------------- # # Block initial recovery after a full cluster restart until N nodes are started: # #gateway.recover_after_nodes: 3 # # For more information, consult the gateway module documentation. # # ---------------------------------- Various ----------------------------------- # # Require explicit names when deleting indices: # #action.destructive_requires_name: true 启动elasticsearch #  bin/elasticsearch -d 部署elasticHD #  yum install xdg-utils "},{"id":23,"href":"/docs/golang/sync/","title":"golang sync包的使用","section":"Go语言笔记","content":" 本文介绍go sync包的用法示例\n type Once #  功能: 确保函数只执行一次\n结构定义：\ntype Once struct { // contains filtered or unexported fields } //function list： func (o *Once) Do(f func()) 用法示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var once sync.Once var two sync.Once onceBody := func() { fmt.Println(\u0026#34;Only once\u0026#34;) } twoBody := func() { fmt.Println(\u0026#34;two once\u0026#34;) } done := make(chan bool) for i := 0; i \u0026lt; 10; i++ { go func() { once.Do(onceBody) done \u0026lt;- true }() } for i := 0; i \u0026lt; 10; i++ { \u0026lt;-done } two.Do(twoBody) two.Do(twoBody) } 输出：\nOnly once two once  type WaitGroup #  功能： 用于等待协程结束，每起一个goroutine之前Add(1),每个goroutine完成退出前Done()，主线程中用Wait()阻塞等待所有goroutine退出。\n结构定义：\ntype WaitGroup struct { // contains filtered or unexported fields } //function list: // 计数器增加delta，表示增加delta个goroutine func (wg *WaitGroup) Add(delta int) // 计数器减1，表示一个goroutine执行完成 func (wg *WaitGroup) Done() // 挂起等待计数器归零 func (wg *WaitGroup) Wait() 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func tt(wg *sync.WaitGroup, i int) { defer wg.Done() fmt.Printf(\u0026#34;goroutine: %d\\n\u0026#34;, i) } func main() { wg := \u0026amp;sync.WaitGroup{} for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go tt(wg, i) } wg.Wait() fmt.Println(\u0026#34;Run end!\u0026#34;) } 输出：\ngoroutine: 9 goroutine: 6 goroutine: 7 goroutine: 8 goroutine: 3 goroutine: 2 goroutine: 4 goroutine: 1 goroutine: 5 goroutine: 0 Run end!  type Locker #  功能： 确保资源只被一个goroutine占有\n结构定义：\ntype Locker interface { Lock() // 上锁，在已锁的状态下此函数阻塞，直到锁被释放  Unlock() // 用于释放锁，在无锁的状态下执行会报错 } 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func tt(w *sync.WaitGroup, l *sync.Mutex, i int) { defer func() { fmt.Printf(\u0026#34;End Goroutine: %d\\n\u0026#34;, i) l.Unlock() w.Done() }() l.Lock() fmt.Printf(\u0026#34;lock: %d\\n\u0026#34;, i) time.Sleep(time.Second) } func main() { l := \u0026amp;sync.Mutex{} w := \u0026amp;sync.WaitGroup{} for i := 0; i \u0026lt; 10; i++ { w.Add(1) go tt(w, l, i) } w.Wait() fmt.Println(\u0026#34;Run end!\u0026#34;) } 输出：\nlock: 1 End Goroutine: 1 lock: 9 End Goroutine: 9 lock: 2 End Goroutine: 2 lock: 3 End Goroutine: 3 lock: 4 End Goroutine: 4 lock: 5 End Goroutine: 5 lock: 6 End Goroutine: 6 lock: 7 End Goroutine: 7 lock: 8 End Goroutine: 8 lock: 0 End Goroutine: 0 Run end!  type RWMutex #  功能： RWMutex 是单写多读锁，读锁占用的情况下会阻止写，不会阻止读，多个goroutine可以同时获取读锁，写锁会阻止其他goroutine（无论读和写）进来，整个锁由该 goroutine独占，适用于读多写少的场景.\nPS：读共享，写独占，写优先\n结构定义：\ntype RWMutex struct { // contains filtered or unexported fields } //function list func (rw *RWMutex) Lock() // 写加锁 func (rw *RWMutex) RLock() // 读加锁 // 返回一个实现Lock和Unlock方法的Locker接口，用于调用rw.RLock和rw.RUnlock来实现读锁的加锁和解锁。 func (rw *RWMutex) RLocker() Locker func (rw *RWMutex) RUnlock() // 读解锁 func (rw *RWMutex) Unlock() // 写解锁 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var value int func writes(i int, wg *sync.WaitGroup, rwM *sync.RWMutex) { defer wg.Done() for { rand.Seed(time.Now().Unix()) num := rand.Intn(100) rwM.Lock() value = num fmt.Printf(\u0026#34;writes goroutine:%d, Write num=%d\\n\u0026#34;, i, num) rwM.Unlock() time.Sleep(time.Second * time.Duration(i+1)) } } func readRLocker(i int, wg *sync.WaitGroup, rwM *sync.RWMutex) { defer wg.Done() w := rwM.RLocker() for { w.Lock() num := value fmt.Printf(\u0026#34;readRLocker goroutine:%d, Reading num=%d\\n\u0026#34;, i, num) time.Sleep(time.Second * 2) w.Unlock() time.Sleep(time.Second * 1) } } func read2(i int, wg *sync.WaitGroup, rwM *sync.RWMutex) { defer wg.Done() for { rwM.RLock() num := value fmt.Printf(\u0026#34;read2 goroutine:%d, Reading num=%d\\n\u0026#34;, i, num) time.Sleep(time.Second * 2) rwM.RUnlock() time.Sleep(time.Second * 1) } } func main() { rwMutex := \u0026amp;sync.RWMutex{} wg := \u0026amp;sync.WaitGroup{} for i := 0; i \u0026lt; 5; i++ { wg.Add(1) go writes(i, wg, rwMutex) } for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go readRLocker(i, wg, rwMutex) } for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go read2(i, wg, rwMutex) } wg.Wait() } 输出：\nwrites goroutine:1, Write num=70 read2 goroutine:1, Reading num=70 read2 goroutine:6, Reading num=70 read2 goroutine:9, Reading num=70 read2 goroutine:7, Reading num=70 read2 goroutine:8, Reading num=70 read2 goroutine:4, Reading num=70 readRLocker goroutine:4, Reading num=70 readRLocker goroutine:1, Reading num=70 readRLocker goroutine:0, Reading num=70 readRLocker goroutine:8, Reading num=70 readRLocker goroutine:3, Reading num=70 readRLocker goroutine:2, Reading num=70 readRLocker goroutine:5, Reading num=70 readRLocker goroutine:9, Reading num=70 readRLocker goroutine:6, Reading num=70 read2 goroutine:2, Reading num=70 read2 goroutine:0, Reading num=70 read2 goroutine:3, Reading num=70 readRLocker goroutine:7, Reading num=70 read2 goroutine:5, Reading num=70 writes goroutine:0, Write num=70 writes goroutine:3, Write num=70 writes goroutine:2, Write num=70 writes goroutine:4, Write num=70 writes goroutine:1, Write num=93 readRLocker goroutine:5, Reading num=93 readRLocker goroutine:8, Reading num=93 read2 goroutine:4, Reading num=93 read2 goroutine:9, Reading num=93 read2 goroutine:7, Reading num=93 read2 goroutine:2, Reading num=93 read2 goroutine:8, Reading num=93 read2 goroutine:5, Reading num=93 readRLocker goroutine:0, Reading num=93 readRLocker goroutine:1, Reading num=93 readRLocker goroutine:3, Reading num=93 readRLocker goroutine:2, Reading num=93 readRLocker goroutine:4, Reading num=93 ··· ···  type Cond  #  功能：\n Broadcase、Signal 唤醒因wait condition而挂起goroutine，Signal只唤醒一个，而Broadcast唤醒所有。允许调用者获取基础锁Locker之后再调用唤醒，但非必需。\n  Wait 必须获取该锁之后才能调用Wait()方法，Wait方法在调用时会释放底层锁Locker，并且将当前goroutine挂起，直到另一个goroutine执行Signal或者Broadcase，该goroutine才有机会重新唤醒，并尝试获取Locker，完成后续逻辑。\n 结构定义：\ntype Cond struct { // L is held while observing or changing the condition  L Locker // contains filtered or unexported fields } //function list: func NewCond(l Locker) *Cond func (c *Cond) Broadcast() // 广播唤醒所有wait func (c *Cond) Signal() // 唤醒其中一个wait func (c *Cond) Wait() // 进入等待状态，释放锁 示例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func tt(cd *sync.Cond, wg *sync.WaitGroup, i int) { defer wg.Done() cd.L.Lock() fmt.Printf(\u0026#34;lock: %d\\n\u0026#34;, i) cd.Wait() fmt.Printf(\u0026#34;wait end: %d\\n\u0026#34;, i) cd.L.Unlock() } func main() { l := \u0026amp;sync.Mutex{} w := \u0026amp;sync.WaitGroup{} cd := sync.NewCond(l) for i := 0; i \u0026lt; 10; i++ { w.Add(1) go tt(cd, w, i) } time.Sleep(time.Second) fmt.Println(\u0026#34;Send 5 Signal:\u0026#34;) for i := 0; i \u0026lt; 5; i++ { cd.Signal() //唤醒一个wait中的goroutine \t} time.Sleep(time.Second) fmt.Println(\u0026#34;Send Broadcast:\u0026#34;) cd.Broadcast() //广播唤醒所有wait中的goroutine \tw.Wait() fmt.Println(\u0026#34;Run end!\u0026#34;) } 输出：\nlock: 1 lock: 2 lock: 7 lock: 8 lock: 9 lock: 0 lock: 3 lock: 6 lock: 5 lock: 4 Send 5 Signal: wait end: 7 wait end: 9 wait end: 2 wait end: 8 wait end: 1 Send Broadcast: wait end: 4 wait end: 0 wait end: 3 wait end: 6 wait end: 5 Run end!  type Pool #  功能： Pool 是可伸缩、并发安全的临时对象池，用来存放已经分配但暂时不用的临时对象，通过对象重用机制，缓解 GC 压力，提高程序性能。\nPS：如果你使用的Pool代码所需的东西不是大概同质的，那么从Pool中转化检索到所需要的内容的时间可能比重新实例化内容要花费的时间更多。\n结构定义：\ntype Pool struct { // New optionally specifies a function to generate  // a value when Get would otherwise return nil.  // It may not be changed concurrently with calls to Get.  New func() interface{} // contains filtered or unexported fields } //function list: func (p *Pool) Get() interface{} //从 Pool 中获取元素，元素数量 -1，当 Pool 中没有元素时，会调用 New 生成元素，新元素不会放入 Pool 中，若 New 未定义，则返回 nil func (p *Pool) Put(x interface{}) // 把用完的元素放回Pool中 示例：\npackage poolTest import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) func connectToService() interface{} { time.Sleep(1 * time.Second) return struct {}{} } func startNetworkDaemon() *sync.WaitGroup { var wg sync.WaitGroup wg.Add(1) go func() { connPool := warmServiceConnCache() server, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;localhost:8080\u0026#34;) if err != nil { log.Fatalf(\u0026#34;cannot listen: %v\u0026#34;, err) } defer server.Close() wg.Done() for { conn, err := server.Accept() if err != nil { log.Printf(\u0026#34;cannot accept connection: %v\u0026#34;, err) } svcConn := connPool.Get() fmt.Fprintln(conn, \u0026#34;\u0026#34;) connPool.Put(svcConn) conn.Close() } }() return \u0026amp;wg } func init() { daemonStarted := startNetworkDaemon() daemonStarted.Wait() } func BenchmarkNetworkRequest(b *testing.B) { for i := 0; i \u0026lt; b.N; i++ { conn, err := net.Dial(\u0026#34;tcp\u0026#34;, \u0026#34;localhost:8080\u0026#34;) if err != nil { b.Fatalf(\u0026#34;cannot dial host: %v\u0026#34;, err) } if _, err := ioutil.ReadAll(conn); err != nil { b.Fatalf(\u0026#34;cannot read: %v\u0026#34;, err) } conn.Close() } } func warmServiceConnCache() *sync.Pool { p := \u0026amp;sync.Pool{ New: connectToService, } for i := 0; i \u0026lt; 10; i++ { p.Put(p.New()) } return p } 输出：\ngoos: darwin goarch: amd64 pkg: go-bfzd/poolTest BenchmarkNetworkRequest-4 1000 10610437 ns/op PASS ok go-bfzd/poolTest 38.099s  type Map #  功能： sync.Map这个数据结构是线程安全的（基本类型Map结构体在并发读写时会panic严重错误），它填补了Map线程不安全的缺陷，不过最好只在需要的情况下使用。它一般用于并发模型中对同一类map结构体的读写，或其他适用于sync.Map的情况。\n结构定义：\ntype Map struct { // contains filtered or unexported fields } //function list: func (m *Map) Delete(key interface{}) // 删除对应key的值 func (m *Map) Load(key interface{}) (value interface{}, ok bool) // 获取key对应的值 func (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool) //获取对应key的值，成功则返回true和value，不存在该key则将值存进该key并返回false和存进去的value func (m *Map) Range(f func(key, value interface{}) bool) // 遍历map中的所有key func (m *Map) Store(key, value interface{}) // 将value存进对应的key，存在则覆盖 示例：\n// sync.Map是线程安全的，一般用于并发模型中，本例不存在并发，只演示各个接口的用法  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { sMap := sync.Map{} fmt.Println(\u0026#34;=====================Store=======================\u0026#34;) fmt.Println(\u0026#34;store: key=1, value=jay\u0026#34;) sMap.Store(1, \u0026#34;jay\u0026#34;) fmt.Println(\u0026#34;store: key=2, value=lhj\u0026#34;) sMap.Store(2, \u0026#34;lhj\u0026#34;) fmt.Println(\u0026#34;store: key=2, value=lhj-hhh\u0026#34;) sMap.Store(2, \u0026#34;lhj-hhh\u0026#34;) fmt.Println(\u0026#34;=====================LoadOrStore=======================\u0026#34;) result, succeed := sMap.LoadOrStore(1, \u0026#34;jays\u0026#34;) fmt.Printf(\u0026#34;key=1 store: value=jays; result: load_succeed=%t, value=%v\\n\u0026#34;, succeed, result) result, succeed = sMap.LoadOrStore(2, \u0026#34;lhj-s\u0026#34;) fmt.Printf(\u0026#34;key=2 store: value=lhj-s; result: load_succeed=%t, value=%v\\n\u0026#34;, succeed, result) result, succeed = sMap.LoadOrStore(3, \u0026#34;jay-lhj\u0026#34;) fmt.Printf(\u0026#34;key=3 store: value=jay-lhj; result: load_succeed=%t, value=%v\\n\u0026#34;, succeed, result) fmt.Println(\u0026#34;=====================Load key:1~4=======================\u0026#34;) if val, ok := sMap.Load(1); ok { fmt.Printf(\u0026#34;key=1, value=%v\\n\u0026#34;, val) }else { fmt.Printf(\u0026#34;key=1, load failed\\n\u0026#34;) } if val, ok := sMap.Load(2); ok { fmt.Printf(\u0026#34;key=2, value=%v\\n\u0026#34;, val) }else { fmt.Printf(\u0026#34;key=2, load failed\\n\u0026#34;) } if val, ok := sMap.Load(3); ok { fmt.Printf(\u0026#34;key=3, value=%v\\n\u0026#34;, val) }else { fmt.Printf(\u0026#34;key=3, load failed\\n\u0026#34;) } if val, ok := sMap.Load(4); ok { fmt.Printf(\u0026#34;key=4, value=%v\\n\u0026#34;, val) }else { fmt.Printf(\u0026#34;key=4, load failed\\n\u0026#34;) } fmt.Println(\u0026#34;======================Delete======================\u0026#34;) fmt.Println(\u0026#34;delete key=1\u0026#34;) sMap.Delete(1) fmt.Println(\u0026#34;=====================Range=======================\u0026#34;) sMap.Range(func(key, value interface{}) bool { fmt.Printf(\u0026#34;key=%v value=%v\\n\u0026#34;, key, value) return true }) } 输出：\n=====================Store======================= store: key=1, value=jay store: key=2, value=lhj store: key=2, value=lhj-hhh =====================LoadOrStore======================= key=1 store: value=jays; result: load_succeed=true, value=jay key=2 store: value=lhj-s; result: load_succeed=true, value=lhj-hhh key=3 store: value=jay-lhj; result: load_succeed=false, value=jay-lhj =====================Load key:1~4======================= key=1, value=jay key=2, value=lhj-hhh key=3, value=jay-lhj key=4, load failed ======================Delete====================== delete key=1 =====================Range======================= key=2 value=lhj-hhh key=3 value=jay-lhj "},{"id":24,"href":"/docs/golang/study-line/","title":"go服务端开发学习指南","section":"Go语言笔记","content":" 本文介绍基于go语言的服务端程序开发学习指南，根据列举的知识点自行学习，所列知识点都是开发基础必备技术栈。\n 熟练Linux系统的使用 #   Linux的基本命令操作 必须熟练Linux系统的使用，才能得心应手的部署自己开发的服务端程序。 shell脚本的编写 编写一下自动化脚本，用于控制服务器的一些自动操作，如起停服，备份，批量操作文件等等。 系统其他配置等 熟悉Linux系统和一些常用软件的配置等，才能让系统更加适配自己的服务端程序的运行，即运行环境的配置。 make和Makefile等 makefile用于配置程序的编译法则，make即编译程序 ps：基础学习可以参考： 菜鸟教程  语言基础 #   golang的语法学习： golang菜鸟教程  数据结构与算法 #   队列，大顶堆，小顶堆，红黑树，字典树 八大排序算法，雪花算法等 缓存的过期策略：FIFO，LRU，LFU等  数据库 #    Redis 用于做缓存,队列,主题订阅发布等\n  MongoDB 结构化不强的数据存储\n  MySQL 结构化数据存储\n  etcd 服务注册与发现\n  Elasticsearch 搜索，数据分析\n  开发框架 #   gin go-kit go-zero kratos beego gRpc zap  架构知识 #   分布式 微服务  其他知识点 #   rpc protobuf http TCP websocket Docker Kubernetes  golang工程师学习之路 # "},{"id":25,"href":"/docs/golang/grace-exit/","title":"go程序优雅退出","section":"Go语言笔记","content":" 本文介绍go程序借助系统信号主动停止服务的实现，即程序优雅退出\n 原理 #  通过Notify方法将捕获的signal发送到channel，总而主动停止相关服务\nfunc Notify(c chan\u0026lt;- os.Signal, sig ...os.Signal) 用法：\nsig := make(chan os.Signal) // 创建信号channel signal.Notify(sig, os.Kill, syscall.SIGINT) //捕获信号 \u0026lt;-sig //信号channel阻塞 代码 #  package main import ( \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;time\u0026#34; ) func main() { wait := \u0026amp;sync.WaitGroup{} wait.Add(1) go func() { sig := make(chan os.Signal) signal.Notify(sig, os.Kill, os.Interrupt, syscall.SIGINT) t := time.Tick(time.Second) for { select { case \u0026lt;-sig: log.Printf(\u0026#34;Goroutine has exit !\u0026#34;) wait.Done() return case \u0026lt;-t: log.Printf(\u0026#34;Goroutine are running ...\u0026#34;) } } }() wait.Wait() } 输出\n2020/03/10 21:19:16 Goroutine are running ... 2020/03/10 21:19:17 Goroutine are running ... 2020/03/10 21:19:18 Goroutine are running ... 2020/03/10 21:19:19 Goroutine are running ... 2020/03/10 21:19:20 Goroutine are running ... 2020/03/10 21:19:21 Goroutine are running ... 2020/03/10 21:19:22 Goroutine are running ... 2020/03/10 21:19:23 Goroutine are running ... 2020/03/10 21:19:24 Goroutine are running ... ^C2020/03/10 21:19:24 Goroutine has exit ! "},{"id":26,"href":"/docs/golang/eventhub/","title":"go程序发布监听事件库","section":"Go语言笔记","content":" 这是一个开源的用于golang程序内部发布和监听事件的package， 其原理是通过定义一个全局变量存储监听的事件id和对应的handle函数， 当发布事件时，通过事件id查找对应的handle，如果找到则执行该handle函数。\n 使用说明 #  安装 #  go get github.com/jageros/eventhub\n使用 #  监听事件 #   seq := eventhub.Subscribe(eventID, handle) eventID为事件id， 返回的seq为序列号，两者都是int型， handle原型为func(args \u0026hellip;interface{}){}，args参数类型为interface{}型，通过事件发布函数传入\n 发布事件 #   eventhub.Publish(eventID, arg1, arg2 ··· ) eventID为事件id， argx为参数，将传给事件监听的handle\n 取消监听 #   Unsubscribe(eventID int, seq int) eventID为事件id， seq为序列号，序列从监听事件函数返回值获得\n 使用示例 #  github.com/jageros/eventhub/example/main.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/jageros/eventhub\u0026#34; ) func main() { // 监听事件 \teventhub.Subscribe(2, func(args ...interface{}) { fmt.Printf(\u0026#34;Subscribe1 eventId=2 args=%v\\n\u0026#34;, args) }) eventhub.Subscribe(1, func(args ...interface{}) { fmt.Printf(\u0026#34;Subscribe2 eventId=1 args=%v\\n\u0026#34;, args) }) eventhub.Subscribe(3, func(args ...interface{}) { fmt.Printf(\u0026#34;Subscribe3 eventId=3 args=%v\\n\u0026#34;, args) if arg, ok := args[0].(func()); ok { arg() } }) // 监听并取消监听 \tseq := eventhub.Subscribe(1, func(args ...interface{}) { fmt.Printf(\u0026#34;Subscribe4 eventId=1 args=%+v\\n\u0026#34;, args) }) eventhub.Unsubscribe(1, seq) // 发布事件 \teventhub.Publish(1, 10, 100) eventhub.Publish(2, 20, 200) eventhub.Publish(3, test) } // 此函数用作参数 func test() { fmt.Printf(\u0026#34;End!\\n\u0026#34;) } 源码解释 #  eventhub.go\npackage eventhub import ( \u0026#34;fmt\u0026#34; ) var ( maxSeq = 0 // 序列号 \tlisteners = make(map[int][]*listener) // map[事件id][]handleFunc ) type listener struct { seq int handler func(args ...interface{}) } /**************************************************************** * func：监听事件函数 * eventID： 事件id * handler： 事件函数 * return seq ： 该事件当前handle的序列号， 用于取消监听时参数 ***************************************************************/ func Subscribe(eventID int, handler func(args ...interface{})) (seq int) { maxSeq++ seq = maxSeq ln := \u0026amp;listener{ seq: seq, handler: handler, } ls, ok := listeners[eventID] if !ok { ls = []*listener{} } listeners[eventID] = append(ls, ln) return seq } /******************************************* * func： 发布事件 * eventID 事件id * args 给handle传的参数 * return nil *******************************************/ func Publish(eventID int, args ...interface{}) { ls, ok := listeners[eventID] if !ok { return } for _, l := range ls { catchPanic(func() { l.handler(args...) }) } } /************************************* * func： 取消监听 * eventID 事件ID * seq 事件序列号 （ps：因为一个事件可能存在多个handle函数） * return nil *************************************/ func Unsubscribe(eventID int, seq int) { ls, ok := listeners[eventID] if !ok { return } index := -1 for i, l := range ls { if l.seq == seq { index = i break } } if index \u0026gt;= 0 { listeners[eventID] = append(ls[:index], ls[index+1:]...) } } /******************************************* * func： 对执行的handle捕获异常并恢复 * f 需要执行法人函数 * return err 执行f返回的错误 *******************************************/ func catchPanic(f func()) (err interface{}) { defer func() { err = recover() if err != nil { fmt.Printf(\u0026#34;eventhub func panic: %s\u0026#34;, err) } }() f() return } "},{"id":27,"href":"/docs/linux/operate-recode/","title":"Linux不常用操作记录","section":"Linux","content":" 本文记录一些Linux的不常用且难以记忆的命令，供以后需要使用可以翻阅\n 批量重命名图片 #  let n=0; for i in *.jpg; do mv $i $n.jpg; n=`expr $n + 1`; done 递归删除指定类型文件 #  find . -name \u0026#34;*.rej\u0026#34; |xargs rm -f 批量修改文件指定内容 #  将文件中的gopkg.in/mgo.v2/bson修改成go.mongodb.org/mongo-driver/bson\n# --include=*.go 表示指定文件类型 grep gopkg.in/mgo.v2/bson -rl --include=*.go ./* | xargs sed -i \u0026#34;s#gopkg.in/mgo.v2/bson#go.mongodb.org/mongo-driver/bson#g\u0026#34; # 或 sed -i \u0026#34;s#gopkg.in/mgo.v2/bson#go.mongodb.org/mongo-driver/bson#g\u0026#34; `grep gopkg.in/mgo.v2/bson -rl --include=\u0026#34;*.go\u0026#34; ./` 查看端口占用 #  lsof -i:8080 # 或 netstat -pan | grep 8080 #netstat 中参数选项 #-a或--all：显示所有连线中的Socket；  #-A\u0026lt;网络类型\u0026gt;或--\u0026lt;网络类型\u0026gt;：列出该网络类型连线中的相关地址；  #-c或--continuous：持续列出网络状态；  #-C或--cache：显示路由器配置的快取信息；  #-e或--extend：显示网络其他相关信息；  #-F或--fib：显示FIB；  #-g或--groups：显示多重广播功能群组组员名单；  #-h或--help：在线帮助；  #-i或--interfaces：显示网络界面信息表单；  #-l或--listening：显示监控中的服务器的Socket；  #-M或--masquerade：显示伪装的网络连线；  #-n或--numeric：直接使用ip地址，而不通过域名服务器；  #-N或--netlink或--symbolic：显示网络硬件外围设备的符号连接名称；  #-o或--timers：显示计时器；  #-p或--programs：显示正在使用Socket的程序识别码和程序名称；  #-r或--route：显示Routing Table；  #-s或--statistice：显示网络工作信息统计表；  #-t或--tcp：显示TCP传输协议的连线状况；  #-u或--udp：显示UDP传输协议的连线状况；  #-v或--verbose：显示指令执行过程；  #-V或--version：显示版本信息；  #-w或--raw：显示RAW传输协议的连线状况；  #-x或--unix：此参数的效果和指定\u0026#34;-A unix\u0026#34;参数相同；  #--ip或--inet：此参数的效果和指定\u0026#34;-A inet\u0026#34;参数相同。 修改终端显示信息 #   配置文件： /etc/bashrc\n PS1=”[\\u@\\h \\w]$” \\d ：代表日期，格式为weekday month date，例如：”Mon Aug 1” \\H ：完整的主机名称。例如：我的机器名称为：fc4.linux，则这个名称就是fc4.linux \\h ：仅取主机的第一个名字，如上例，则为fc4，.linux则被省略 \\t ：显示时间为24小时格式，如：HH：MM：SS \\T ：显示时间为12小时格式 \\A ：显示时间为24小时格式：HH：MM \\u ：当前用户的账号名称 \\v ：BASH的版本信息 \\w ：完整的工作目录名称。家目录会以 ~代替 \\W ：利用basename取得工作目录名称，所以只会列出最后一个目录 # ：下达的第几个命令 $ ：提示字符，如果是root时，提示符为：# ，普通用户则为：$ 查看系统参数 #  # 查看Linux版本 cat /proc/version # 查看Linux发行版本 cat /etc/redhat-release # 查看CPU型号及参数 cat /proc/cpuinfo | grep model # 查看磁盘空间 df -h # 查看内存和交换空间 free -[k/m/g] #k/m/g分别表示以kb，mb，gb为单位显示`` # 查看系统位数 getconf LONG_BIT linux文件修改权限 #  命令: chmod ABC file 其中A、B、C各为一个数字，分别表示User、Group、及Other的权限。 A、B、C这三个数字如果各自转换成由“0”、“1”组成的二进制数，则二进制数的每一位分别代表一个角色的读、写、运行的权限。比如User组的权限A： 如果可读、可写、可运行，就表示为二进制的111，转换成十进制就是7。 如果可读、可写、不可运行，就表示为二进制的110，转换成十进制就是6。 如果可读、不可写、可运行，就表示为二进制的101，转换成十进制就是5。 “4=r,2=w,1=x”的意思是： r 代表读，w 代表写，x 代表执行， 如果可读，权限是二进制的100，十进制是4； 如果可写，权限是二进制的010，十进制是2； 如果可运行，权限是二进制的001，十进制是1； 具备多个权限，就把相应的 4、2、1 相加就可以了： 若要 rwx 则 4+2+1=7 若要 rw- 则 4+2=6 若要 r-x 则 4+1=5 若要 r-- 则 =4 若要 -wx 则 2+1=3 若要 -w- 则 =2 若要 --x 则 =1 若要 --- 则 =0 为不同的角色分配不同的权限，放在一起，就出现 777、677这样的数字了。 你也可以用 chmod u+x file 的方式为User组添加执行权限。 chmod +x file 是为当前用户添加执行权限 "},{"id":28,"href":"/docs/nginx/nginx-limit/","title":"Nginx IP 限流","section":"Nginx","content":" 通过对同一IP进行限流，在一定程度上可以防止应用层DDOS攻击。本文介绍 Nginx对同一IP限流的配置\n nginx.conf配置文件 #  http { ...... # 在http节点中添加下面这一行 limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; server { # 在server节点中添加这一行 limit_req zone=one burst=10 nodelay;; ...... } } limit_req_zone的参数详解:\nbinary_remote_addr：表示客户端ip地址的二进制，当此nginx前方还存在代理时，需进行处理.\nzone=one:10m：为session会话状态分配一个大小为10m内存存储区，并且设定名称为one.\nrate=1r/s：表示请求频率不能超过每秒一次.\n limit_req的参数详解:\nzone=one：表示这个server服务收到的请求放在one的那个内存区域，等待被处理.\nburst=10：表示请求队列的长度，比如我设置了rate=1r/s，而同一时刻有15个请求发过来，那么第一个请求会被处理，10个请求会被存在队列里等待被处理，而剩下4个请求就会直接响应503状态码。\nnodelay：表示不延时。比如rate=1r/s，如果不设置nodelay就会严格按照1秒处理一个请求的频率，直观的看就是页面数据卡了，过了一秒后才加载出来。\n 这里有人就会疑惑了，既然nodelay设置不延时，那么设置处理频率rate=1r/s又有什么意义呢?\n我们假设一个案例来做分析：\n 设置rate=1r/s，burst=10，nodelay不延时，然后同时有15个请求发过来，其中一个请求被处理的时候，有10个请求会在队列中等待，而另外4个请求就会直接响应503状态码。由于设置了nodelay，一旦处理完一个请求之后立刻就会处理队列中的下一个请求。在1秒钟内，队列钟的请求全部都被处理完了，但是这个时候队列中的请求并不会被清除掉，而是会等到满1秒钟后才会被清除。这期间如果还有请求发来，由于队列中的请求并没有被清除，所以直接就响应503。\n "},{"id":29,"href":"/docs/nginx/proxy/","title":"nginx反向代理","section":"Nginx","content":" 利用Nginx的反向代理可以实现多个域名指向同个服务器的不同网站，本文将介绍如何配置\n nginx反向代理配置 #  第一个站点\nserver { listen 443; server_name www.jayg.xyz; ssl on; ssl_certificate /home/www/ssl/1_www.jayg.xyz_bundle.crt; ssl_certificate_key /home/www/ssl/2_www.jayg.xyz.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; location / { proxy_pass http://127.0.0.1:8080; } error_page 500 502 503 504 404 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } 第二个站点\nserver { listen 443 ssl; server_name www.hawtech.cn; ssl_certificate /home/www/ssl/1_www.hawtech.cn_bundle.crt; ssl_certificate_key /home/www/ssl/2_www.hawtech.cn.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; location / { proxy_pass http://127.0.0.1:8081; } error_page 500 502 503 504 404 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } "},{"id":30,"href":"/docs/golang/queue/","title":"queue golang实现","section":"Go语言笔记","content":" 本文介绍go语言queue库的原理，代码解析以及使用方法\n 说明 #   本文主要介绍golang queue 库：gopkg.in/eapache/queue的实现原理和使用。\n第三方开源库获取： go get gopkg.in/eapache/queue.v1 使用时导入： import \u0026quot;gopkg.in/eapache/queue.v1\u0026quot;\n 原理 #   队列的缓存区为环形，实际是一个数组，当队头元素取出后，队头标志会往后移动，空出的位置可存储队尾新加元素，当队尾增加元素时，队尾标志向后移动，当缓存区我末尾没有位置时，队尾标志从0开始，复用队头取出元素空出的位置，直到当缓存区满后，缓存区空间成倍增长【ps: resize中的newBuf := make([]interface{}, q.count\u0026lt;\u0026lt;1)】，队列元素复制到缓存区的开始区域，当队列元素数量减为缓存区1/4的时候，缓存区空间重置为元素个数的两倍长度，同时队列元素复制到缓存区的开始区域。\n 函数功能 #  queue.New()返回一个长度为16的空队列 queue.Add(elem)为入队，即向队列中添加元素 queue.Remove()为出队列操作，返回一个队头元素 queue.Peek()返回队头元素，但元素不出队 queue.Get(i)返回队列中第i个元素，但不从队列中删除  源码解读 #  ps： 该库主要是这个文件： queue.go，源码不多，开发者可根据需求修改后使用\n/* Package queue provides a fast, ring-buffer queue based on the version suggested by Dariusz Górecki. Using this instead of other, simpler, queue implementations (slice+append or linked list) provides substantial memory and time benefits, and fewer GC pauses. The queue implemented here is as fast as it is for an additional reason: it is *not* thread-safe. */ package queue // minQueueLen is smallest capacity that queue may have. // Must be power of 2 for bitwise modulus: x % n == x \u0026amp; (n - 1). const minQueueLen = 16 // 队列缓存区最小长度  // Queue represents a single instance of the queue data structure. type Queue struct { buf []interface{} // 缓存区 \thead, tail, count int // 队头下标，队尾下标，队列长度 } // New constructs and returns a new Queue. func New() *Queue { return \u0026amp;Queue{ buf: make([]interface{}, minQueueLen), // 返回最小长度缓存的空队列 \t} } // Length returns the number of elements currently stored in the queue. func (q *Queue) Length() int { return q.count // 队列长度 } // resizes the queue to fit exactly twice its current contents // this can result in shrinking if the queue is less than half-full func (q *Queue) resize() { newBuf := make([]interface{}, q.count\u0026lt;\u0026lt;1) // 将队列缓存区长度重设为队列长度的两倍  // 复制元素到缓存区开始区域 \tif q.tail \u0026gt; q.head { copy(newBuf, q.buf[q.head:q.tail]) } else { // 因为是环形缓存区，需要先复制缓存区后半部分，即队列前半部分，再复制缓存区前半部分，即队尾部分 \tn := copy(newBuf, q.buf[q.head:]) copy(newBuf[n:], q.buf[:q.tail]) } q.head = 0 // 队头下标置0 \tq.tail = q.count // 队尾下标为队列长度（此下标为下一个元素插入的下标） \tq.buf = newBuf // 新队列 } // Add puts an element on the end of the queue. func (q *Queue) Add(elem interface{}) { if q.count == len(q.buf) { q.resize() // 新元素入队之前，当队列长度等于缓存区长度时，缓存区长度重设为两个队列长度 \t} q.buf[q.tail] = elem // 入队 \t// bitwise modulus \tq.tail = (q.tail + 1) \u0026amp; (len(q.buf) - 1) // 队尾下标在缓存环中移动一位 \tq.count++ // 队列长度+1 } // Peek returns the element at the head of the queue. This call panics // if the queue is empty. func (q *Queue) Peek() interface{} { if q.count \u0026lt;= 0 { panic(\u0026#34;queue: Peek() called on empty queue\u0026#34;) } return q.buf[q.head] // 返回队头元素，不出队 } // Get returns the element at index i in the queue. If the index is // invalid, the call will panic. This method accepts both positive and // negative index values. Index 0 refers to the first element, and // index -1 refers to the last. func (q *Queue) Get(i int) interface{} { // If indexing backwards, convert to positive index. \tif i \u0026lt; 0 { i += q.count // 支持负数，从队列尾部开始 \t} if i \u0026lt; 0 || i \u0026gt;= q.count { panic(\u0026#34;queue: Get() called with index out of range\u0026#34;) } // bitwise modulus \treturn q.buf[(q.head+i)\u0026amp;(len(q.buf)-1)] // 返回队列的第i个元素 \t// 因为数环形缓存区，队尾可能在缓存去前半部分，所以需要与一下队列最大下标 } // Remove removes and returns the element from the front of the queue. If the // queue is empty, the call will panic. func (q *Queue) Remove() interface{} { if q.count \u0026lt;= 0 { panic(\u0026#34;queue: Remove() called on empty queue\u0026#34;) } ret := q.buf[q.head] // 出队 \tq.buf[q.head] = nil // bitwise modulus \tq.head = (q.head + 1) \u0026amp; (len(q.buf) - 1) // 队头下标在环形缓存区后移一位 \tq.count-- // 队列长度减一 \t// Resize down if buffer 1/4 full. \tif len(q.buf) \u0026gt; minQueueLen \u0026amp;\u0026amp; (q.count\u0026lt;\u0026lt;2) == len(q.buf) { q.resize() // 重置缓存区大小，当队列长度减小到缓存区长度1/4的时候，但不可小于最小长度16 \t} return ret } 测试 #   打印缓存区数据，查看缓存区大小变化：\n先在queue.go中添加打印函数\nfunc (q *Queue) LookData() { fmt.Println(q.buf) }  测试代码main.go\npackage main import ( \u0026#34;test_code/queue\u0026#34; ) func main() { que := queue.New() for i := 0; i \u0026lt; 16; i++ { que.Add(i) que.LookData() } for i := 0; i \u0026lt; 5; i++ { que.Remove() que.LookData() } for i := 0; i \u0026lt; 5; i++ { que.Add(i) que.LookData() } que.Add(100) que.LookData() for i := 0; i \u0026lt; 16; i++ { que.Remove() que.LookData() } } 输出：\n[0 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 4 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 4 5 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 4 5 6 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 4 5 6 7 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 4 5 6 7 8 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 4 5 6 7 8 9 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 4 5 6 7 8 9 10 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;nil\u0026gt;] [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15] [\u0026lt;nil\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 2 3 4 5 6 7 8 9 10 11 12 13 14 15] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 3 4 5 6 7 8 9 10 11 12 13 14 15] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 4 5 6 7 8 9 10 11 12 13 14 15] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 5 6 7 8 9 10 11 12 13 14 15] [0 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 5 6 7 8 9 10 11 12 13 14 15] [0 1 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 5 6 7 8 9 10 11 12 13 14 15] [0 1 2 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 5 6 7 8 9 10 11 12 13 14 15] [0 1 2 3 \u0026lt;nil\u0026gt; 5 6 7 8 9 10 11 12 13 14 15] [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15] [5 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; 6 7 8 9 10 11 12 13 14 15 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 7 8 9 10 11 12 13 14 15 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 8 9 10 11 12 13 14 15 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 9 10 11 12 13 14 15 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 10 11 12 13 14 15 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 11 12 13 14 15 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 12 13 14 15 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 13 14 15 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [14 15 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; 15 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 0 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 1 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 2 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 3 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 4 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] [\u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; 100 \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt; \u0026lt;nil\u0026gt;] "},{"id":31,"href":"/docs/golang/tinypng/","title":"批量图片压缩go实现","section":"Go语言笔记","content":" 基于golang和tinypng的图片批量压缩工具实现\n 准备工作 #   首先通过 tinyPNG获得一个api_key用于压缩图片api的验证，输入名称+邮箱，然后打开收到的邮件里的链接即可获得，一个key每月免费500次，即一个月可以压缩500张图片，500张对我个人使用够用了。  然后创建一个码云的公共仓库用来存储压缩后的图片，gitee账号设置里面生成一个access_token用于提交图片。 【PS：如果不用作图床，只需要把压缩后的图片存储到本地的话，可以不需要此步骤】   获取程序 #  配置tinyPNG以及gitee #   更改程序当前路径下的config.toml文件，具体看注释，根据需求选择是否需要填写gitee配置和输出文件夹。  "},{"id":32,"href":"/docs/algorithm/random-n-int/","title":"生成x个随机数","section":"算法知识","content":" 需求：生成x个随机数，要求这个x个随机数的和为y， 且随机数的最大值小于平均数的3倍，最小值大于0，例如：5个和为10的随机数避免出现6，1，1，1，1的情况。 【使用场景：游戏中卡牌包开包时随机出现卡牌质量的分布】\n本文展示go语言对该算法的实现\n 代码实现 #  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;sort\u0026#34; \u0026#34;time\u0026#34; ) func main() { rand.Seed(time.Now().Unix()) // 用时间初始化种子 \tfor i := 0; i \u0026lt; 10; i++ { // 求10次结果 \tfmt.Println(randFewInt(10, 5, 6)) } } /* 实现函数 * f(sum, n) return []int * sum 表示总和，n表示个数， max表示生成的随机数小于max * []int 表示n个随机数 */ func randFewInt(sum, n, max int) []int { var vals, numList []int valSet := map[int]struct{}{} // 最大值不能大于总和 \tmin := float64(sum) / float64(n) if float64(max) \u0026lt;= min { max = int(math.Floor(min)) + 1 } if max \u0026lt; sum { max2 := max // 将0-sum分割成长度小于max的x段 \tfor i := 0; i \u0026lt; n-1; i++ { val := max2 - 1 valSet[val] = struct{}{} max2 = val + max if max2 \u0026gt; sum { break } } } // 把筛选出还没被选中的数 \tvar ls []int for i := 1; i \u0026lt; sum; i++ { if _, ok := valSet[i]; !ok { ls = append(ls, i) } else { vals = append(vals, i) } } // 分割成n段需要n-1个随机数，从筛选出的数中随机出剩余个数的数 \t//log.Printf(\u0026#34; ====== ls=%v vals=%v\u0026#34;, ls, vals) \tremainCnt := n - 1 - len(vals) vals = append(vals, RandIntSample(ls, remainCnt, false)...) // 在n-1个数中加上首端和末端， 即0和sum \tvals = append(vals, 0, sum) // 对n+1个数进行排序 \tsort.Ints(vals) //log.Printf(\u0026#34; ====== raminCnt=%d vals=%v\u0026#34;, remainCnt, vals)  // 求出每一段的长度， 即n个随机数 \tfor i := 1; i \u0026lt; len(vals); i++ { a := vals[i] - vals[i-1] numList = append(numList, a) } return numList } /* 从数组list中随机取n个数 * canRepeat 表示是否可重复 * 取出的数如果不可重复就不会出现0的随机数 */ func RandIntSample(list []int, n int, canRepeat bool) []int { var args []interface{} for _, e := range list { args = append(args, e) } sampleList := RandSample(args, n, canRepeat) var ret []int for _, e := range sampleList { ret = append(ret, e.(int)) } return ret } // 接口化实现， 即可用于任何类型的数组，不只是int型 /* 从数组list中随机取n个数 * canRepeat 表示是否可重复 * 取出的数如果不可重复就不会出现0的随机数 */ func RandSample(list []interface{}, n int, canRepeat bool) []interface{} { if n \u0026lt;= 0 { return []interface{}{} } if !canRepeat \u0026amp;\u0026amp; len(list) \u0026lt;= n { return list } var ret []interface{} var set map[int]struct{} if !canRepeat { set = make(map[int]struct{}) } for len(ret) \u0026lt; n { i := rand.Intn(len(list)) if !canRepeat { if _, ok := set[i]; ok { continue } set[i] = struct{}{} } ret = append(ret, list[i]) } return ret } "},{"id":33,"href":"/docs/golang/other-recode/","title":"零碎笔记","section":"Go语言笔记","content":" 本文记录一些golang程序的一些简短的要点\n 求int64的最大值 #  maxInt64 := int64(^uint64(0)\u0026gt;\u0026gt;1) "},{"id":34,"href":"/docs/kubernetes/kubernetes-setup/","title":"Kubernetes服务部署步骤","section":"Kubernetes","content":" 本文介绍Kubernetes服务部署步骤\n 一、环境要求 #   物理机 × 3 (master × 1 + node × 2)【4核8G】 Linux发行版：CentOS7 Linux内核：3.10.0-1160.25.1.el7.x86_64 docker-ce 18.09.9 k8s v1.16.0  二、Kubernetes集群搭建 #  1、修改机器参数 #  # 分别修改三台机器的主机名 hostnamectl set-hostname master hostnamectl set-hostname node1 hostnamectl set-hostname node2 2、安装docker（所有机器） #  # 安装docker所需的工具 yum install -y yum-utils device-mapper-persistent-data lvm2 # 配置阿里云的docker源 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 指定安装这个版本的docker-ce yum install -y docker-ce-18.09.9-3.el7 # 启动docker systemctl enable docker \u0026amp;\u0026amp; systemctl start docker 3、设置k8s环境变量（所有机器） #  # 关闭防火墙 systemctl disable firewalld systemctl stop firewalld # 关闭selinux # 临时禁用selinux setenforce 0 # 永久关闭 修改/etc/sysconfig/selinux文件设置 sed -i \u0026#39;s/SELINUX=permissive/SELINUX=disabled/\u0026#39; /etc/sysconfig/selinux sed -i \u0026#34;s/SELINUX=enforcing/SELINUX=disabled/g\u0026#34; /etc/selinux/config # 禁用交换分区 swapoff -a # 永久禁用，打开/etc/fstab注释掉swap那一行。 sed -i \u0026#39;s/.*swap.*/#\u0026amp;/\u0026#39; /etc/fstab # 修改内核参数 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system 4、安装配置master节点（只在master操作） #  # 安装kubeadm、kubelet、kubectl # 由于官方k8s源在google，国内无法访问，这里使用阿里云yum源 # 执行配置k8s阿里云源 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 安装kubeadm、kubectl、kubelet yum install -y kubectl-1.16.0-0 kubeadm-1.16.0-0 kubelet-1.16.0-0 # 启动kubelet服务 systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet # 初始化k8s 以下这个命令开始安装k8s需要用到的docker镜像 # 因为无法访问到国外网站，所以这条命令使用的是国内的阿里云的源(registry.aliyuncs.com/google_containers)。 # 另一个非常重要的是：这里的--apiserver-advertise-address使用的是master和node间能互相ping通的master ip，测试环境中是192.168.99.104，请修改成自己的ip再执行。 # 这条命令执行时会卡在[preflight] You can also perform this action in beforehand using \u0026#39;\u0026#39;kubeadm config images pull，大概需要2分钟，请耐心等待。 kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.16.0 --apiserver-advertise-address 192.168.60.143 --pod-network-cidr=10.244.0.0/16 --token-ttl 0 # 上面安装完成后，k8s会提示你输入如下命令，执行 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # 查询node 加入 master的命令 kubeadm token create --print-join-command 5、安装node工作节点（所有node节点） #  # 安装kubeadm、kubelet # 执行配置k8s阿里云源 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 安装kubeadm、kubectl、kubelet yum install -y kubeadm-1.16.0-0 kubelet-1.16.0-0 # 启动kubelet服务 systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet # 加入集群，如果这里不知道加入集群的命令，可以登录master节点，使用kubeadm token create --print-join-command 来获取 kubeadm join 192.168.99.104:6443 --token ncfrid.7ap0xiseuf97gikl \\ --discovery-token-ca-cert-hash sha256:47783e9851a1a517647f1986225f104e81dbfd8fb256ae55ef6d68ce9334c6a2 6、安装flannel网络组件（只在master操作） #  kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml # 安装完成之后，可通过 kubectl get nodes 命令查看所有节点是否都为Ready状态，全为Ready说明节点间网络已打通了 7、部署Ingress控制器：traefik v2.3 #    traefik介绍\n Traefik 是一个边缘路由器。由于 Traefik 2.X 版本和之前的 1.X 版本不兼容，我们这里选择功能更加强大的 2.X 版本来和大家进行讲解，我们这里使用的镜像是 traefik:2.3。\n在 Traefik 中的配置可以使用两种不同的方式：\n 动态配置：完全动态的路由配置 静态配置：启动配置  静态配置中的元素（这些元素不会经常更改）连接到 providers 并定义 Treafik 将要监听的 entrypoints。\n 在 Traefik 中有三种方式定义静态配置：在配置文件中、在命令行参数中、通过环境变量传递\n 动态配置包含定义系统如何处理请求的所有配置内容，这些配置是可以改变的，而且是无缝热更新的，没有任何请求中断或连接损耗。\nps: 具体可参考文章： 一文搞懂 Traefik2.1 的使用\n   创建域名证书验证\n 从域名服务商那里可以免费申请域名的tls证书，将其重名为tls.crt和tls.key\n然后使用下面命令生成k8s的域名验证信息， domain-tls为名称，后续会用到，可自行定义\n kubectl create secret tls domain-tls --cert=tls.crt --key=tls.key   获取traefik安装文件\ngit clone https://github.com/jageros/treafik-profile.git   修改文件配置\n 拉取到的仓库有四个yaml文件，其中crd.yaml和rbac.yaml两个文件是不需要修改的，其他两个需要做如下修改\n # deployment.yaml #通过kubectl get nodes命令可以查看节点名称 ... nodeSelector: kubernetes.io/hostname: master  # master必须为master节点的名称，根据自己的修改 ... # dashboard.yaml ... routes: - match: Host(`www.domain.com`)  # 域名要改成自己的域名 ... ... ... tls: secretName: domain-tls # 这个即上面生成域名验证信息的名称，需要改成相应的   安装traefik\n# 通过shell脚本直接安装即可 sh apply.sh   检查traefik是否正常运行\n[root@master ~]# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-58cc8c89f4-4qq8h 1/1 Running 14 27d coredns-58cc8c89f4-vqj7f 1/1 Running 14 27d etcd-master 1/1 Running 16 27d kube-apiserver-master 1/1 Running 16 27d kube-controller-manager-master 1/1 Running 18 27d kube-flannel-ds-26rkn 1/1 Running 18 27d kube-flannel-ds-68fv6 1/1 Running 16 27d kube-flannel-ds-n827d 1/1 Running 14 27d kube-flannel-ds-w4w2c 1/1 Running 16 27d kube-proxy-6rnfh 1/1 Running 14 27d kube-proxy-m4ck5 1/1 Running 14 27d kube-proxy-rzb4h 1/1 Running 16 27d kube-proxy-sc5px 1/1 Running 14 27d kube-scheduler-master 1/1 Running 18 27d traefik-78878774df-vzsc4 1/1 Running 4 11d   检查是否可外网访问\n 在域名解析中添加解析到master的IP，然后访问域名，看是否可以访问到dashboard UI（如图所示）\n    三、部署应用 #  1、编译应用上传到docker仓库 #    修改编译脚本配置信息\n 编译脚本为项目中的build_all.sh，build_item.sh和Dockerfile文件\n修改build_all.sh中的版本号和build_item.sh中的仓库地址\n然后执行sh build_all.sh编译即可\n   修改服务应用的yaml文件\n 应用的yaml文件在项目目录下的k8s文件夹下面，需要把镜像的版本号修改成对应build_all.sh文件中的\n域名和验证的tls名称也要改成对应的\n   2、部署应用 #    先准备好Etcd、Redis、MongoDB和MySQL，并把配置写入到etcd中\n  把应用的yaml文件打包上传到master机器上\n  通过执行apply.sh脚本即可让应用跑起来\n  3、 测试服务是否正常 #   通过dashborad ui查看路由是否正常 通过kubectl get pods -n yinyin命令查看pod状态是否正常  4、更新应用 #   版本号递增，然后修改yaml中的版本号 应用：kubectl apply -f xxx.yaml  5、停止应用 #  sh delete.sh 参考 #    kube-flannel.yml  traefik教程 "}]